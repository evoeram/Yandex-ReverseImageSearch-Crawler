#!/usr/bin/env python3
"""
–ü—Ä–æ—Å—Ç–æ–π –∑–∞–≥—Ä—É–∑—á–∏–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ SQLite –ë–î –±–µ–∑ –∫–æ–Ω—Ñ–∏–≥–æ–≤.
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç: yandex_images.db ‚Üí –ø–∞–ø–∫–∞ yandex_images
              vk_images.db      ‚Üí –ø–∞–ø–∫–∞ vk_images
–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ–±–∞ URL (url + origin_url) –≤ —Ç—Ä–µ–∫–µ—Ä –∏ –≤ .txt-—Ñ–∞–π–ª —Ä—è–¥–æ–º —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º.
"""

import asyncio
import sqlite3
import hashlib
import mimetypes
import sys
from pathlib import Path
from urllib.parse import urlparse
from typing import Optional

import aiohttp
import aiofiles


# === –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ ===

def normalize_url(url: Optional[str]) -> Optional[str]:
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç URL: –¥–æ–±–∞–≤–ª—è–µ—Ç —Å—Ö–µ–º—É, —É–±–∏—Ä–∞–µ—Ç –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã."""
    if not url or not isinstance(url, str):
        return None
    url = url.strip()
    if url.startswith("//"):
        url = "https:" + url
    if not url.startswith(("http://", "https://")):
        return None
    return url


def get_file_extension(url: str, content_type: Optional[str]) -> str:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ –ø–æ Content-Type –∏–ª–∏ URL."""
    ext = None
    if content_type:
        ct = content_type.split(";")[0].strip()
        ext = mimetypes.guess_extension(ct)
    if not ext:
        parsed = urlparse(url)
        suffix = Path(parsed.path).suffix.lower()
        if suffix and 1 < len(suffix) <= 5 and suffix.count(".") == 1:
            ext = suffix
    return ext if ext and ext.startswith(".") else ".jpg"


def build_local_path(
    download_root: Path,
    image_id: str,
    variant_type: str,
    width: Optional[int],
    height: Optional[int],
    url: str,
) -> Path:
    """–§–æ—Ä–º–∏—Ä—É–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –ø—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è."""
    w = width or 0
    h = height or 0
    url_hash = hashlib.md5(url.encode()).hexdigest()[:8]
    base = f"{image_id}_{variant_type}_{w}x{h}_{url_hash}"
    safe_base = "".join(c if c.isalnum() or c in "._- " else "_" for c in base)
    if len(safe_base) > 200:
        safe_base = safe_base[:150] + "_" + safe_base[-42:]
    return download_root / safe_base


def write_sidecar(
    path: Path,
    url: Optional[str],
    origin_url: Optional[str],
    image_id: str,
    variant_type: str,
    width: Optional[int],
    height: Optional[int],
) -> None:
    """–°–æ–∑–¥–∞—ë—Ç .txt-—Ñ–∞–π–ª —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ —Ä—è–¥–æ–º —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º."""
    sidecar = path.with_suffix(".txt")
    if sidecar.exists():
        return
    try:
        with sidecar.open("w", encoding="utf-8") as f:
            f.write(f"url: {url or ''}\n")
            f.write(f"origin_url: {origin_url or ''}\n")
            f.write(f"image_id: {image_id}\n")
            f.write(f"variant_type: {variant_type}\n")
            f.write(f"width: {width or ''}\n")
            f.write(f"height: {height or ''}\n")
    except Exception:
        pass  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ –∑–∞–ø–∏—Å–∏ —Å–∞–π–¥–∫–∞—Ä–∞


# === –†–∞–±–æ—Ç–∞ —Å –ë–î —Ç—Ä–µ–∫–µ—Ä–∞ ===

def init_tracker_db(tracker_db: Path) -> None:
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ë–î —Ç—Ä–µ–∫–µ—Ä–∞."""
    with sqlite3.connect(tracker_db) as conn:
        conn.execute("""
            CREATE TABLE IF NOT EXISTS download_log (
                variant_id INTEGER PRIMARY KEY,
                image_id TEXT NOT NULL,
                variant_type TEXT NOT NULL,
                url TEXT,
                origin_url TEXT,
                local_path TEXT,
                status TEXT CHECK(status IN ('pending', 'downloaded', 'failed', 'skipped')) DEFAULT 'pending',
                error_message TEXT,
                file_size_bytes INTEGER,
                downloaded_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        conn.commit()


def get_pending_tasks(source_db: Path, tracker_db: Path) -> list:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∑–∞–¥–∞—á–∏, –∫–æ—Ç–æ—Ä—ã–µ –µ—â—ë –Ω–µ –±—ã–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã."""
    try:
        with sqlite3.connect(tracker_db) as conn:
            conn.row_factory = sqlite3.Row
            cur = conn.execute("SELECT variant_id FROM download_log WHERE status = 'downloaded'")
            downloaded = {row["variant_id"] for row in cur.fetchall()}
    except sqlite3.OperationalError:
        downloaded = set()

    with sqlite3.connect(source_db) as conn:
        conn.row_factory = sqlite3.Row
        cur = conn.execute("""
            SELECT id, image_id, variant_type, url, origin_url, width, height
            FROM image_variants
            WHERE url IS NOT NULL OR origin_url IS NOT NULL
        """)
        all_tasks = cur.fetchall()

    return [t for t in all_tasks if t["id"] not in downloaded]


def update_tracker(tracker_db: Path, record: tuple) -> None:
    """–û–±–Ω–æ–≤–ª—è–µ—Ç –∑–∞–ø–∏—Å—å –≤ —Ç—Ä–µ–∫–µ—Ä–µ."""
    with sqlite3.connect(tracker_db) as conn:
        conn.execute("""
            INSERT OR REPLACE INTO download_log
            (variant_id, image_id, variant_type, url, origin_url,
             local_path, status, error_message, file_size_bytes)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, record)
        conn.commit()


def select_download_url(url: Optional[str], origin_url: Optional[str], prefer_origin: bool) -> Optional[str]:
    """–í—ã–±–∏—Ä–∞–µ—Ç URL –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏."""
    if prefer_origin:
        candidate = normalize_url(origin_url)
        if candidate:
            return candidate
    candidate = normalize_url(url)
    return candidate or normalize_url(origin_url)


# === –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π ===

async def download_one(
    session: aiohttp.ClientSession,
    semaphore: asyncio.Semaphore,
    task: sqlite3.Row,
    download_root: Path,
    base_sleep: float,
    retry_attempts: int,
    prefer_origin: bool,
) -> tuple:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –æ–¥–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ."""
    async with semaphore:
        await asyncio.sleep(base_sleep)

        variant_id = task["id"]
        image_id = task["image_id"]
        variant_type = task["variant_type"]
        url = task["url"]
        origin_url = task["origin_url"]
        width = task["width"]
        height = task["height"]

        download_url = select_download_url(url, origin_url, prefer_origin)
        if not download_url:
            return (
                variant_id, image_id, variant_type, url, origin_url,
                None, "skipped", "No valid URL", None
            )

        error_msg = "Unknown error"
        final_path = None

        for attempt in range(retry_attempts + 1):
            try:
                async with session.get(download_url) as resp:
                    resp.raise_for_status()
                    content_type = resp.headers.get("Content-Type", "")
                    ext = get_file_extension(download_url, content_type)
                    final_path = build_local_path(
                        download_root, image_id, variant_type, width, height, download_url
                    ).with_suffix(ext)

                    # –ï—Å–ª–∏ —Ñ–∞–π–ª —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É, –Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                    if final_path.exists():
                        size = final_path.stat().st_size
                        write_sidecar(final_path, url, origin_url, image_id, variant_type, width, height)
                        return (
                            variant_id, image_id, variant_type, url, origin_url,
                            str(final_path), "downloaded", None, size
                        )

                    # –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞
                    final_path.parent.mkdir(parents=True, exist_ok=True)
                    temp_path = final_path.with_suffix(".tmp")
                    total_bytes = 0

                    async with aiofiles.open(temp_path, "wb") as f:
                        async for chunk in resp.content.iter_chunked(8192):
                            if chunk:
                                await f.write(chunk)
                                total_bytes += len(chunk)

                    temp_path.replace(final_path)
                    write_sidecar(final_path, url, origin_url, image_id, variant_type, width, height)
                    return (
                        variant_id, image_id, variant_type, url, origin_url,
                        str(final_path), "downloaded", None, total_bytes
                    )

            except aiohttp.ClientResponseError as e:
                if e.status == 429:
                    retry_after = int(resp.headers.get("Retry-After", 5))
                    await asyncio.sleep(retry_after)
                    continue
                error_msg = f"HTTP {e.status}"
            except (aiohttp.ClientConnectorError, asyncio.TimeoutError):
                error_msg = "Connection/timeout error"
            except aiohttp.ClientError as e:
                error_msg = f"aiohttp error: {type(e).__name__}"
            except (PermissionError, OSError) as e:
                error_msg = f"OS error: {type(e).__name__}"
            except Exception as e:
                error_msg = f"Unexpected: {type(e).__name__}: {str(e)[:100]}"

            if attempt < retry_attempts:
                await asyncio.sleep(1.0)
                continue
            break

        return (
            variant_id, image_id, variant_type, url, origin_url,
            str(final_path) if final_path else None,
            "failed", error_msg, None
        )


async def run_downloads_async(
    source_db: Path,
    download_root: Path,
    tracker_db: Path,
    max_workers: int,
    prefer_origin: bool,
    show_progress: bool,
) -> None:
    """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏."""
    init_tracker_db(tracker_db)
    tasks = get_pending_tasks(source_db, tracker_db)
    print(f"–ù–∞–π–¥–µ–Ω–æ –∑–∞–¥–∞—á –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏: {len(tasks):,}")

    if not tasks:
        generate_report(tracker_db)
        return

    semaphore = asyncio.Semaphore(max_workers)
    connector = aiohttp.TCPConnector(limit=max_workers)
    timeout = aiohttp.ClientTimeout(total=40, connect=10)
    user_agent = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"

    async with aiohttp.ClientSession(
        connector=connector,
        timeout=timeout,
        headers={"User-Agent": user_agent},
    ) as session:
        coros = [
            download_one(
                session, semaphore, task,
                download_root, base_sleep=0.05,
                retry_attempts=3, prefer_origin=prefer_origin
            )
            for task in tasks
        ]

        if show_progress:
            try:
                from tqdm import tqdm
                with tqdm(total=len(coros), desc="üì• –ó–∞–≥—Ä—É–∑–∫–∞", unit="—Ñ–∞–π–ª") as pbar:
                    for future in asyncio.as_completed(coros):
                        result = await future
                        update_tracker(tracker_db, result)
                        pbar.update(1)
            except ImportError:
                show_progress = False
                print("tqdm –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω ‚Äî –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä –æ—Ç–∫–ª—é—á—ë–Ω.")

        if not show_progress:
            for future in asyncio.as_completed(coros):
                result = await future
                update_tracker(tracker_db, result)

    generate_report(tracker_db)


def generate_report(tracker_db: Path) -> None:
    """–í—ã–≤–æ–¥–∏—Ç –∏—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á—ë—Ç."""
    with sqlite3.connect(tracker_db) as conn:
        cur = conn.cursor()
        cur.execute("SELECT status, COUNT(*) FROM download_log GROUP BY status")
        summary = dict(cur.fetchall())

        def top_errors(status: str):
            cur.execute("""
                SELECT error_message, COUNT(*) as cnt
                FROM download_log
                WHERE status = ? AND error_message IS NOT NULL
                GROUP BY error_message
                ORDER BY cnt DESC
                LIMIT 10
            """, (status,))
            return cur.fetchall()

        top_failed = top_errors("failed")
        top_skipped = top_errors("skipped")

    total = sum(summary.values())
    downloaded = summary.get("downloaded", 0)
    failed = summary.get("failed", 0)
    skipped = summary.get("skipped", 0)

    print("\n" + "=" * 70)
    print("‚úÖ –ó–ê–ì–†–£–ó–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê ‚Äî –ò–¢–û–ì–û–í–´–ô –û–¢–ß–Å–¢")
    print("=" * 70)
    print(f"–í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {total:,}")
    print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ:       {downloaded:,} ({downloaded / total * 100:.1f}%)")
    print(f"‚ùå –û—à–∏–±–∫–∏:        {failed:,} ({failed / total * 100:.1f}%)")
    print(f"‚è≠Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω–æ:    {skipped:,} ({skipped / total * 100:.1f}%)")

    if top_failed:
        print("\nüîç –¢–æ–ø-10 –ø—Ä–∏—á–∏–Ω –æ—à–∏–±–æ–∫:")
        for msg, cnt in top_failed:
            print(f"  ‚Ä¢ {msg} ‚Üí {cnt}")

    if top_skipped:
        print("\n‚è≠Ô∏è  –¢–æ–ø-10 –ø—Ä–∏—á–∏–Ω –ø—Ä–æ–ø—É—Å–∫–æ–≤:")
        for msg, cnt in top_skipped:
            print(f"  ‚Ä¢ {msg} ‚Üí {cnt}")

    print(f"\nüìä –¢—Ä–µ–∫–µ—Ä: {tracker_db}")
    print("=" * 70)


# === –¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ ===

def main() -> None:
    print("–í—ã–±–µ—Ä–∏—Ç–µ –∏—Å—Ç–æ—á–Ω–∏–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:")
    print("1) yandex_images.db  ‚Üí —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –ø–∞–ø–∫—É yandex_images")
    print("2) vk_images.db      ‚Üí —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –ø–∞–ø–∫—É vk_images")
    choice = input("–í–≤–µ–¥–∏—Ç–µ 1 –∏–ª–∏ 2: ").strip()

    if choice == "1":
        source_db = Path("yandex_images.db")
        download_root = Path("yandex_images")
    elif choice == "2":
        source_db = Path("vk_images.db")
        download_root = Path("vk_images")
    else:
        print("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä. –í—ã—Ö–æ–¥.")
        sys.exit(1)

    if not source_db.exists():
        print(f"‚ùå –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {source_db}")
        sys.exit(1)

    download_root.mkdir(exist_ok=True)
    tracker_db = download_root / "tracker.db"

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ tqdm –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞
    try:
        import tqdm  # noqa: F401
        show_progress = True
    except ImportError:
        show_progress = False
        print("‚ÑπÔ∏è  tqdm –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω ‚Äî –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –æ—Ç–∫–ª—é—á–µ–Ω–æ.")

    print(f"\nüöÄ –ó–∞–ø—É—Å–∫ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑ {source_db} –≤ {download_root}")
    print(f"   –¢—Ä–µ–∫–µ—Ä: {tracker_db}")
    print(f"   –ü–æ—Ç–æ–∫–æ–≤: 40")
    print()

    try:
        asyncio.run(
            run_downloads_async(
                source_db=source_db,
                download_root=download_root,
                tracker_db=tracker_db,
                max_workers=40,
                prefer_origin=False,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º url, fallback –Ω–∞ origin_url
                show_progress=show_progress,
            )
        )
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è  –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º.")
        sys.exit(130)


if __name__ == "__main__":
    main()